"""
简单应用题 2：分词去重

参考编程模板，完善代码，实现以下功能。‪‬‪‬‪‬‪‬‪‬‮‬‫‬‭‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‫‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‮‬

利用 jieba 库实现中文分词。对分词后的列表进行去重处理，然后将分词结果中字符数大于等于 3 的词语，按照字符顺序排序，写入到文件 out1.txt 文件中。‪‬‪‬‪‬‪‬‪‬‮‬‫‬‫‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‮‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‫‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‭‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‫‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‮‬

out1.txt 文件中每一行是分词后的一个词语。形式如下所示：‪‬‪‬‪‬‪‬‪‬‮‬‫‬‫‬‪‬‪‬‪‬‪‬‪‬‮‬‪‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‮‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‪‬‪‬‪‬‪‬‪‬‪‬‮‬‫‬‫‬
"""

# 请在...处使用多行代码替换
#
# 注意：其他已给出代码仅作为提示，可以修改

# ...  #此处可多行
# 对数据进行中文分词处理
import jieba
f = open('out1.txt','w')
##with open("data.txt","r",encoding="utf-8") as fi :  # with不用close()
##    print(fi.read())
fi = open("data.txt","r",encoding="utf-8")
word_list = jieba.lcut(fi.read())  # 分词
words = set(word_list)  # 去重
ls_words = list(words)  # 先转为list再排序
sorted_words = sorted(ls_words)  # 排序
##ls_sorted_words = list(sorted_words)  # 先排序再转为list也可，有序后的set也是长期有序的
for word in sorted_words :
    if len(word) >= 3 :
        f.write(word + "\n")
fi.close()
f.close()
